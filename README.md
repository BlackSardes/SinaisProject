<<<<<<< HEAD
# GPS Spoofing Detection Project

**Disciplina**: ES413 - Sinais e Sistemas  
**InstituiÃ§Ã£o**: Cin/UFPE  
**Objetivo**: DetecÃ§Ã£o de ataques de spoofing em sinais GPS usando processamento de sinais e machine learning

---

## ðŸ“‹ Ãndice

- [VisÃ£o Geral](#visÃ£o-geral)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [Uso RÃ¡pido](#uso-rÃ¡pido)
- [Datasets](#datasets)
- [Pipeline Completa](#pipeline-completa)
- [MÃ³dulos](#mÃ³dulos)
- [Notebooks](#notebooks)
- [Testes](#testes)
- [DocumentaÃ§Ã£o](#documentaÃ§Ã£o)
- [Contribuindo](#contribuindo)

---

## ðŸŽ¯ VisÃ£o Geral

Este projeto implementa uma pipeline completa para detecÃ§Ã£o de spoofing em sinais GPS L1 C/A, incluindo:

- **PrÃ©-processamento robusto**: NormalizaÃ§Ã£o, filtragem, remoÃ§Ã£o de DC, windowing
- **ExtraÃ§Ã£o de features**: MÃ©tricas de correlaÃ§Ã£o (FWHM, P/S ratio, assimetria), C/N0, features temporais
- **ClassificaÃ§Ã£o**: Random Forest, SVM, MLP com tratamento de desbalanceamento
- **AvaliaÃ§Ã£o**: MÃ©tricas completas (accuracy, precision, recall, F1, ROC-AUC)
- **VisualizaÃ§Ãµes**: Confusion matrix, ROC curves, feature distributions

**Diferencial**: Todas as decisÃµes tÃ©cnicas sÃ£o fundamentadas em conceitos de **Sinais e Sistemas** (veja [DECISIONS.md](docs/DECISIONS.md)).

---

## ðŸ“ Estrutura do Projeto

```
SinaisProject/
â”œâ”€â”€ data/                          # Dados GPS (nÃ£o versionados)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ docs/                          # DocumentaÃ§Ã£o
â”‚   â””â”€â”€ DECISIONS.md              # Justificativas tÃ©cnicas detalhadas
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ EDA.ipynb                 # AnÃ¡lise exploratÃ³ria
â”‚   â”œâ”€â”€ feature_demo.ipynb        # DemonstraÃ§Ã£o de features
â”‚   â””â”€â”€ training_eval.ipynb       # Treinamento e avaliaÃ§Ã£o
â”œâ”€â”€ scripts/                       # Scripts executÃ¡veis
â”‚   â””â”€â”€ run_pipeline.py           # Pipeline completa
â”œâ”€â”€ src/                          # CÃ³digo fonte
â”‚   â”œâ”€â”€ preprocessing/            # PrÃ©-processamento de sinais
â”‚   â”‚   â”œâ”€â”€ signal_io.py         # Leitura de sinais (bin, csv, mat)
â”‚   â”‚   â”œâ”€â”€ normalization.py     # NormalizaÃ§Ã£o e remoÃ§Ã£o DC
â”‚   â”‚   â”œâ”€â”€ filtering.py         # Filtros passa-banda, notch
â”‚   â”‚   â”œâ”€â”€ windowing.py         # SegmentaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ cn0_estimation.py    # EstimaÃ§Ã£o C/N0
â”‚   â”‚   â””â”€â”€ resampling.py        # Reamostragem
â”‚   â”œâ”€â”€ features/                 # ExtraÃ§Ã£o de features
â”‚   â”‚   â”œâ”€â”€ correlation.py       # CorrelaÃ§Ã£o cruzada/auto
â”‚   â”‚   â”œâ”€â”€ correlation_features.py  # Features do perfil (FWHM, P/S, etc)
â”‚   â”‚   â”œâ”€â”€ temporal_features.py # Features temporais
â”‚   â”‚   â””â”€â”€ feature_pipeline.py  # Pipeline de features
â”‚   â”œâ”€â”€ models/                   # Modelos de classificaÃ§Ã£o
â”‚   â”‚   â”œâ”€â”€ classifiers.py       # Random Forest, SVM, MLP
â”‚   â”‚   â”œâ”€â”€ training.py          # Treinamento (com/sem SMOTE)
â”‚   â”‚   â”œâ”€â”€ evaluation.py        # MÃ©tricas e avaliaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ persistence.py       # Save/load modelos
â”‚   â””â”€â”€ utils/                    # UtilitÃ¡rios
â”‚       â”œâ”€â”€ plots.py             # VisualizaÃ§Ãµes
â”‚       â””â”€â”€ synthetic_data.py    # Gerador de dados sintÃ©ticos
â”œâ”€â”€ tests/                        # Testes unitÃ¡rios
â”œâ”€â”€ results/                      # Resultados (nÃ£o versionados)
â”œâ”€â”€ requirements.txt              # DependÃªncias Python
â”œâ”€â”€ environment.yml               # Ambiente conda
â””â”€â”€ README.md                     # Este arquivo
```

---

## ðŸš€ InstalaÃ§Ã£o

### OpÃ§Ã£o 1: pip (Recomendado)

```bash
# Clone o repositÃ³rio
git clone https://github.com/BlackSardes/SinaisProject.git
cd SinaisProject

# Crie ambiente virtual
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instale dependÃªncias
pip install -r requirements.txt
```

### OpÃ§Ã£o 2: conda

```bash
# Clone o repositÃ³rio
git clone https://github.com/BlackSardes/SinaisProject.git
cd SinaisProject

# Crie ambiente conda
conda env create -f environment.yml
conda activate gps-spoofing
```

### DependÃªncias Principais

- **Essenciais**: numpy, scipy, pandas, scikit-learn, matplotlib, seaborn
- **ML AvanÃ§ado**: imbalanced-learn (SMOTE)
- **PersistÃªncia**: joblib
- **Notebooks**: jupyter
- **Testes**: pytest

**Nota**: TensorFlow/Keras e librosa estÃ£o comentados em `requirements.txt` e `environment.yml` (dependÃªncias pesadas opcionais).

---

## âš¡ Uso RÃ¡pido

### 1. Executar Pipeline com Dados SintÃ©ticos

```bash
# Pipeline completa com dados sintÃ©ticos
python scripts/run_pipeline.py --synthetic --n-authentic 200 --n-spoofed 200

# Com SMOTE para balanceamento
python scripts/run_pipeline.py --synthetic --use-smote

# Escolher modelo diferente
python scripts/run_pipeline.py --synthetic --model svm
```

**SaÃ­da**: Modelo treinado, relatÃ³rio de avaliaÃ§Ã£o, visualizaÃ§Ãµes em `results/`

### 2. Usar MÃ³dulos Individualmente

```python
# Gerar dados sintÃ©ticos
from src.utils.synthetic_data import generate_synthetic_dataset
signals, labels = generate_synthetic_dataset(n_authentic=100, n_spoofed=100)

# Extrair features
from src.features.feature_pipeline import build_feature_vector
features_df = build_feature_vector(signals, fs=5e6, prn=1)
features_df['label'] = labels

# Treinar modelo
from src.models.training import train_model
X = features_df.drop(['segment_id', 'label'], axis=1).values
y = features_df['label'].values
model, info = train_model(X, y, model_name='random_forest')

# Avaliar
from src.models.evaluation import evaluate_model
metrics = evaluate_model(model, info['X_test'], info['y_test'])
print(f"Accuracy: {metrics['test_accuracy']:.3f}")
```

---

## ðŸ“Š Datasets

### Dados SintÃ©ticos (Inclusos)

O projeto inclui gerador de sinais GPS sintÃ©ticos para testes:
- CÃ³digo C/A vÃ¡lido
- RuÃ­do Gaussiano
- OpÃ§Ã£o de adicionar sinal de spoofing com delay e potÃªncia configurÃ¡veis

```python
from src.utils.synthetic_data import generate_synthetic_gps_signal

# Sinal autÃªntico
signal_auth = generate_synthetic_gps_signal(duration_s=0.5, cn0_db=45)

# Sinal com spoofing
signal_spoof = generate_synthetic_gps_signal(
    duration_s=0.5, cn0_db=45, add_spoofing=True,
    spoofing_delay_chips=0.3, spoofing_power_ratio=2.0
)
```

### Dataset Real: FGI-SpoofRepo (Opcional)

Para usar dados reais, baixe o **FGI-SpoofRepo**:

1. **Download**: https://github.com/nlsfi/FGI-GSRx/tree/master/Spoofing%20Dataset

2. **Estrutura recomendada**:
```
data/
â””â”€â”€ FGI-SpoofRepo/
    â”œâ”€â”€ scenario1/
    â”‚   â”œâ”€â”€ signal_authentic.bin
    â”‚   â””â”€â”€ signal_spoofed.bin
    â”œâ”€â”€ scenario2/
    â””â”€â”€ ...
```

3. **ParÃ¢metros tÃ­picos**:
   - Formato: int16 interleaved I/Q
   - Taxa de amostragem: 5-26 MHz (varia por cenÃ¡rio)
   - PRNs: mÃºltiplos (1-32)

4. **Carregar sinal**:
```python
from src.preprocessing.signal_io import load_signal

signal = load_signal(
    'data/FGI-SpoofRepo/scenario1/signal.bin',
    file_format='binary',
    count_samples=int(0.5 * 5e6)  # 0.5s @ 5 MHz
)
```

**Nota**: Implementar rotulagem automÃ¡tica baseada em timestamps do FGI (veja `docs/DECISIONS.md` seÃ§Ã£o 7).

---

## ðŸ”¬ Pipeline Completa

A pipeline segue estas etapas:

```
1. Carregamento/GeraÃ§Ã£o de Sinais
   â†“
2. PrÃ©-processamento
   - NormalizaÃ§Ã£o de potÃªncia
   - RemoÃ§Ã£o DC
   - Filtragem (opcional)
   â†“
3. SegmentaÃ§Ã£o (Windowing)
   - Janelas de 0.5-1s
   - Overlap de 50%
   â†“
4. ExtraÃ§Ã£o de Features
   - CorrelaÃ§Ã£o com cÃ³digo C/A
   - Features do perfil: FWHM, P/S ratio, assimetria
   - C/N0 e variaÃ§Ã£o temporal
   - Features estatÃ­sticas
   â†“
5. PrÃ©-processamento de Features
   - ImputaÃ§Ã£o de valores faltantes
   - PadronizaÃ§Ã£o (StandardScaler)
   - PCA (opcional)
   â†“
6. Treinamento
   - Random Forest (class_weight='balanced')
   - OpÃ§Ã£o: SMOTE para balanceamento
   - ValidaÃ§Ã£o cruzada
   â†“
7. AvaliaÃ§Ã£o
   - MÃ©tricas: accuracy, precision, recall, F1, ROC-AUC
   - Confusion matrix
   - Feature importance
   â†“
8. PersistÃªncia
   - Salvar modelo (.pkl)
   - Salvar metadados (.json)
   - Salvar visualizaÃ§Ãµes
```

---

## ðŸ§© MÃ³dulos

### src/preprocessing

FunÃ§Ãµes de prÃ©-processamento de sinais GPS:
- `load_signal()`: Carrega sinais de mÃºltiplos formatos (.bin, .csv, .mat)
- `normalize_signal()`: NormalizaÃ§Ã£o de potÃªncia
- `bandpass_filter()`: Filtro passa-banda Butterworth
- `window_segment()`: SegmentaÃ§Ã£o em janelas
- `estimate_cn0_from_correlation()`: EstimaÃ§Ã£o de C/N0

### src/features

ExtraÃ§Ã£o de features para classificaÃ§Ã£o:
- `compute_cross_correlation()`: CorrelaÃ§Ã£o rÃ¡pida via FFT
- `extract_correlation_features()`: FWHM, P/S ratio, assimetria, etc.
- `extract_temporal_features()`: Features estatÃ­sticas do sinal
- `build_feature_vector()`: Pipeline completa de features

### src/models

Treinamento e avaliaÃ§Ã£o de modelos:
- `train_model()`: Treina Random Forest/SVM/MLP
- `train_with_smote()`: Treina com balanceamento SMOTE
- `evaluate_model()`: MÃ©tricas completas
- `save_model()`, `load_model()`: PersistÃªncia

### src/utils

UtilitÃ¡rios e visualizaÃ§Ãµes:
- `plot_confusion_matrix()`: Matriz de confusÃ£o
- `plot_roc_curves()`: Curvas ROC
- `plot_feature_distributions()`: DistribuiÃ§Ã£o de features por classe
- `generate_synthetic_gps_signal()`: Gerador de sinais sintÃ©ticos

---

## ðŸ““ Notebooks

### 1. EDA.ipynb - AnÃ¡lise ExploratÃ³ria

- VisualizaÃ§Ã£o de sinais GPS
- AnÃ¡lise de perfis de correlaÃ§Ã£o
- DistribuiÃ§Ã£o de features
- ComparaÃ§Ã£o autÃªntico vs spoofed

### 2. feature_demo.ipynb - DemonstraÃ§Ã£o de Features

- ExtraÃ§Ã£o passo-a-passo de features
- VisualizaÃ§Ã£o de FWHM, P/S ratio
- AnÃ¡lise de sensibilidade
- InterpretaÃ§Ã£o fÃ­sica

### 3. training_eval.ipynb - Treinamento e AvaliaÃ§Ã£o

- Treinamento de mÃºltiplos modelos
- ComparaÃ§Ã£o de performance
- AnÃ¡lise de feature importance
- Tuning de hiperparÃ¢metros

**Para executar**:
=======

# SinaisProject - GPS Spoofing Detection

A robust machine learning pipeline for detecting GPS spoofing attacks using signal processing and classification techniques. This project was developed for the Signals and Systems (ES413) course.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Installation](#installation)
- [Project Structure](#project-structure)
- [Quick Start](#quick-start)
- [Usage](#usage)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [License](#license)

## ðŸŽ¯ Overview

GPS spoofing is a security threat where false GPS signals are transmitted to deceive receivers. This project implements a complete pipeline for detecting such attacks by analyzing:

- **Correlation peak distortions**: Spoofing creates multiple peaks or asymmetric patterns
- **Power anomalies**: Spoofing signals often have higher power (C/N0) than authentic signals
- **Statistical features**: Distribution changes in signal properties

The pipeline uses machine learning models (Random Forest, SVM, Neural Networks) trained on features extracted from GPS signal correlation functions.

## âœ¨ Features

### Signal Processing
- Multi-format signal loading (binary, MATLAB, CSV, synthetic)
- GPS C/A code generation for all PRN satellites (1-32)
- Comprehensive preprocessing pipeline:
  - DC offset removal
  - Frequency correction (Doppler/IF)
  - Interference mitigation (pulse blanking, frequency domain)
  - Bandpass and notch filtering
  - Signal normalization

### Feature Extraction
- **Correlation-based features**:
  - Peak-to-secondary ratio
  - Full Width at Half Maximum (FWHM)
  - Peak asymmetry
  - Skewness and kurtosis
  - Energy distribution
  
- **Power metrics**:
  - C/N0 estimation
  - SNR calculation
  - Noise floor analysis
  
- **Statistical features**:
  - Distribution moments
  - Spectral characteristics
  - Temporal patterns

### Machine Learning
- Multiple model support (Random Forest, SVM, MLP)
- Class imbalance handling (SMOTE, class weights)
- Stratified cross-validation
- Comprehensive evaluation metrics
- Model persistence (save/load)

### Visualization
- Correlation profile plots
- Feature distribution analysis
- Confusion matrices
- ROC curves
- Feature importance rankings
- C/N0 temporal evolution

## ðŸ› ï¸ Installation

### Prerequisites
- Python 3.9 or higher
- pip or conda package manager

### Using pip

```bash
# Clone the repository
git clone https://github.com/BlackSardes/SinaisProject.git
cd SinaisProject

# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Using conda

```bash
# Clone the repository
git clone https://github.com/BlackSardes/SinaisProject.git
cd SinaisProject

# Create conda environment
conda env create -f environment.yml
conda activate sinaisproject
```

## ðŸ“ Project Structure

```
SinaisProject/
â”œâ”€â”€ data/                          # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                       # Raw signal files
â”‚   â””â”€â”€ processed/                 # Processed features
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb
â”‚   â”œâ”€â”€ 02_feature_extraction_demo.ipynb
â”‚   â””â”€â”€ 03_model_training_evaluation.ipynb
â”œâ”€â”€ src/                           # Source code
â”‚   â”œâ”€â”€ preprocessing/             # Signal preprocessing
â”‚   â”‚   â”œâ”€â”€ signal_io.py          # I/O operations
â”‚   â”‚   â”œâ”€â”€ signal_processing.py  # Processing functions
â”‚   â”‚   â”œâ”€â”€ prn_codes.py          # PRN code generation
â”‚   â”‚   â””â”€â”€ pipeline.py           # Complete pipeline
â”‚   â”œâ”€â”€ features/                  # Feature extraction
â”‚   â”‚   â”œâ”€â”€ correlation.py        # Correlation features
â”‚   â”‚   â”œâ”€â”€ statistical.py        # Statistical features
â”‚   â”‚   â””â”€â”€ pipeline.py           # Feature pipeline
â”‚   â”œâ”€â”€ models/                    # Machine learning models
â”‚   â”‚   â”œâ”€â”€ training.py           # Training functions
â”‚   â”‚   â””â”€â”€ evaluation.py         # Evaluation metrics
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â””â”€â”€ plots.py              # Visualization functions
â”œâ”€â”€ tests/                         # Unit tests
â”œâ”€â”€ scripts/                       # Executable scripts
â”‚   â””â”€â”€ run_pipeline.py           # End-to-end pipeline
â”œâ”€â”€ docs/                          # Documentation
â”‚   â””â”€â”€ DECISIONS.md              # Technical decisions
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ environment.yml                # Conda environment
â””â”€â”€ README.md                      # This file
```

## ðŸš€ Quick Start

### 1. Synthetic Signal Example

```python
from src.preprocessing.signal_io import generate_synthetic_signal
from src.preprocessing.pipeline import preprocess_signal
from src.features.pipeline import extract_features_from_segment

# Generate synthetic GPS signal
signal = generate_synthetic_signal(
    num_samples=50000,
    fs=5e6,
    snr_db=10.0,
    prn=1,
    add_spoofing=True
)

# Preprocess
signal_processed = preprocess_signal(signal, fs=5e6)

# Extract features
features = extract_features_from_segment(
    signal_processed,
    fs=5e6,
    prn=1
)

print(f"Extracted {len(features)} features")
```

### 2. Process Real Data File

```python
from src.features.pipeline import extract_features_from_file

# Define labeling function (TEXBAT dataset example)
def label_func(time_s):
    return 1 if time_s >= 17.0 else 0  # Spoofing starts at 17s

# Extract features from entire file
features_df = extract_features_from_file(
    file_path='data/raw/signal.bin',
    fs=5e6,
    prn=1,
    segment_duration=0.5,
    label_func=label_func,
    verbose=True
)

print(features_df.head())
```

### 3. Train and Evaluate Model

```python
from src.models.training import train_model, create_train_test_split
from src.models.evaluation import evaluate_model
from src.utils.plots import plot_confusion_matrix, plot_roc_curve

# Prepare data
X = features_df.drop(columns=['label', 'segment_start_time']).values
y = features_df['label'].values

# Split data
X_train, X_test, y_train, y_test = create_train_test_split(X, y)

# Train model
model, cv_results = train_model(
    X_train, y_train,
    model_name='random_forest',
    balance_method='class_weight'
)

# Evaluate
results = evaluate_model(model, X_test, y_test)

# Visualize
plot_confusion_matrix(results['confusion_matrix'])
```

## ðŸ“– Usage

### Complete Pipeline Script

Run the end-to-end pipeline:

```bash
python scripts/run_pipeline.py --data-dir data/raw --output-dir results
```

### Jupyter Notebooks

Explore the interactive notebooks:

>>>>>>> main
```bash
jupyter notebook notebooks/
```

<<<<<<< HEAD
---

## ðŸ§ª Testes

Execute testes unitÃ¡rios:

```bash
# Todos os testes
pytest tests/

# Com cobertura
pytest tests/ --cov=src --cov-report=html

# Teste especÃ­fico
pytest tests/test_features.py::test_fwhm_computation
```

**Testes implementados**:
- GeraÃ§Ã£o de cÃ³digo C/A
- NormalizaÃ§Ã£o de sinal
- CÃ¡lculo de FWHM
- Pipeline mÃ­nima com dados sintÃ©ticos
- PersistÃªncia de modelos

---

## ðŸ“š DocumentaÃ§Ã£o

### docs/DECISIONS.md

Documento **essencial** que explica:
- Fundamentos de Sinais e Sistemas
- Justificativa para cada decisÃ£o tÃ©cnica
- InterpretaÃ§Ã£o fÃ­sica de cada feature
- Trade-offs de modelos e mÃ©todos
- LimitaÃ§Ãµes e trabalhos futuros

**Leitura obrigatÃ³ria** para entender o projeto em profundidade.

---

## ðŸ¤ Contribuindo

1. Fork o repositÃ³rio
2. Crie branch para feature: `git checkout -b feature/nova-feature`
3. Commit: `git commit -m 'Add nova feature'`
4. Push: `git push origin feature/nova-feature`
5. Abra Pull Request

**Diretrizes**:
- Docstrings em todas as funÃ§Ãµes
- Testes para novas funcionalidades
- Justificar decisÃµes tÃ©cnicas

---

## ðŸ“„ LicenÃ§a

Este projeto Ã© de cÃ³digo aberto para fins educacionais (ES413).

---

## ðŸ‘¥ Autores

Equipe ES413 - Sinais e Sistemas  
Centro de InformÃ¡tica - UFPE

---

## ðŸ“ž Contato

Para dÃºvidas ou sugestÃµes, abra uma **Issue** no GitHub.

---

**Ãšltima atualizaÃ§Ã£o**: Dezembro 2024
=======
1. **01_exploratory_analysis.ipynb**: Dataset exploration and visualization
2. **02_feature_extraction_demo.ipynb**: Feature extraction walkthrough
3. **03_model_training_evaluation.ipynb**: Model training and comparison

### Adding New Datasets

1. Place signal files in `data/raw/`
2. Supported formats:
   - Binary I/Q files (`.bin`, `.dat`): TEXBAT/FGI format
   - MATLAB files (`.mat`): Must contain 'signal' or 'I'/'Q' variables
   - CSV files (`.csv`): Two columns (I, Q)

3. Define labeling function based on your dataset:

```python
def custom_label_func(time_s):
    # Return 1 for spoofed segments, 0 for authentic
    if time_s >= SPOOF_START_TIME:
        return 1
    return 0
```

## ðŸ“š Documentation

Detailed documentation is available in the `docs/` directory:

- **[DECISIONS.md](docs/DECISIONS.md)**: Technical decisions and justifications
  - Why specific features were chosen
  - Signal processing techniques explained
  - Algorithm selection rationale
  - Connection to Signal and Systems theory

### Key Concepts

#### Signal Processing Pipeline
1. **DC Removal**: Removes hardware-induced offset
2. **Frequency Correction**: Compensates for Doppler and IF
3. **Interference Mitigation**: Suppresses RFI and impulsive noise
4. **Normalization**: Standardizes power levels

#### Feature Extraction
- **Peak-to-Secondary Ratio**: Measures correlation peak purity (decreases with spoofing)
- **Asymmetry**: Quantifies peak imbalance (increases with overlapping signals)
- **C/N0**: Carrier-to-noise density ratio (increases in power attacks)

#### Models
- **Random Forest**: Best overall performance, handles non-linear relationships
- **SVM**: Good for high-dimensional feature spaces
- **MLP**: Neural network for complex pattern learning

## ðŸ§ª Testing

Run unit tests:

```bash
python -m pytest tests/
```

Run specific test module:

```bash
python -m pytest tests/test_preprocessing.py -v
```

## ðŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“„ License

This project is developed for academic purposes as part of the ES413 course.

## ðŸ™ Acknowledgments

- **TEXBAT Dataset**: GPS spoofing test dataset
- **IS-GPS-200**: GPS Interface Specification for C/A code generation
- **Course**: Sinais e Sistemas (ES413)

## ðŸ“§ Contact

For questions or issues, please open an issue on GitHub.

---

**Note**: This project requires GPS signal data to function. Synthetic signals can be generated for testing, but real spoofing detection requires authentic datasets like TEXBAT or FGI.
>>>>>>> main
