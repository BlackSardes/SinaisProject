{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS Spoofing Detection - Quick Start\n",
    "\n",
    "This notebook demonstrates the basic usage of the GPS spoofing detection pipeline with synthetic signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from src.preprocessing.signal_io import generate_synthetic_signal\n",
    "from src.preprocessing.pipeline import preprocess_signal\n",
    "from src.features.pipeline import extract_features_from_segment\n",
    "from src.models.training import train_model, create_train_test_split\n",
    "from src.models.evaluation import evaluate_model\n",
    "from src.utils.plots import plot_confusion_matrix, plot_feature_distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic GPS Signals\n",
    "\n",
    "We'll create synthetic signals with and without spoofing to build a test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "fs = 5e6  # 5 MHz sampling rate\n",
    "prn = 1   # PRN satellite 1\n",
    "segment_duration = 0.5  # seconds\n",
    "num_samples = int(fs * segment_duration)\n",
    "\n",
    "# Generate authentic signal\n",
    "signal_authentic = generate_synthetic_signal(\n",
    "    num_samples=num_samples,\n",
    "    fs=fs,\n",
    "    snr_db=10.0,\n",
    "    prn=prn,\n",
    "    add_spoofing=False\n",
    ")\n",
    "\n",
    "# Generate spoofed signal\n",
    "signal_spoofed = generate_synthetic_signal(\n",
    "    num_samples=num_samples,\n",
    "    fs=fs,\n",
    "    snr_db=15.0,  # Higher SNR for spoofing signal\n",
    "    prn=prn,\n",
    "    add_spoofing=True\n",
    ")\n",
    "\n",
    "print(f\"Generated signals: {num_samples} samples each\")\n",
    "print(f\"Authentic signal power: {np.mean(np.abs(signal_authentic)**2):.2f}\")\n",
    "print(f\"Spoofed signal power: {np.mean(np.abs(signal_spoofed)**2):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess Signals\n",
    "\n",
    "Apply preprocessing pipeline to clean and normalize the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess both signals\n",
    "signal_authentic_processed = preprocess_signal(signal_authentic, fs)\n",
    "signal_spoofed_processed = preprocess_signal(signal_spoofed, fs)\n",
    "\n",
    "print(\"Signals preprocessed successfully\")\n",
    "print(f\"Processed authentic power: {np.mean(np.abs(signal_authentic_processed)**2):.3f}\")\n",
    "print(f\"Processed spoofed power: {np.mean(np.abs(signal_spoofed_processed)**2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Features\n",
    "\n",
    "Extract correlation-based and statistical features from the signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from authentic signal\n",
    "features_authentic = extract_features_from_segment(\n",
    "    signal_authentic_processed,\n",
    "    fs=fs,\n",
    "    prn=prn,\n",
    "    include_statistical=True\n",
    ")\n",
    "\n",
    "# Extract features from spoofed signal\n",
    "features_spoofed = extract_features_from_segment(\n",
    "    signal_spoofed_processed,\n",
    "    fs=fs,\n",
    "    prn=prn,\n",
    "    include_statistical=True\n",
    ")\n",
    "\n",
    "print(f\"Extracted {len(features_authentic)} features\")\n",
    "print(\"\\nKey feature comparison:\")\n",
    "print(f\"  Peak-to-Secondary Ratio:\")\n",
    "print(f\"    Authentic: {features_authentic['peak_to_secondary']:.2f}\")\n",
    "print(f\"    Spoofed:   {features_spoofed['peak_to_secondary']:.2f}\")\n",
    "print(f\"  C/N0 Estimate:\")\n",
    "print(f\"    Authentic: {features_authentic['cn0_estimate']:.2f} dB-Hz\")\n",
    "print(f\"    Spoofed:   {features_spoofed['cn0_estimate']:.2f} dB-Hz\")\n",
    "print(f\"  Asymmetry:\")\n",
    "print(f\"    Authentic: {features_authentic['asymmetry']:.4f}\")\n",
    "print(f\"    Spoofed:   {features_spoofed['asymmetry']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Dataset\n",
    "\n",
    "Generate a larger dataset with multiple segments for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dataset\n",
    "n_segments = 100\n",
    "features_list = []\n",
    "\n",
    "for i in range(n_segments):\n",
    "    # Half authentic, half spoofed\n",
    "    is_spoofed = i >= n_segments // 2\n",
    "    \n",
    "    signal = generate_synthetic_signal(\n",
    "        num_samples=num_samples,\n",
    "        fs=fs,\n",
    "        snr_db=15.0 if is_spoofed else 10.0,\n",
    "        prn=prn,\n",
    "        add_spoofing=is_spoofed\n",
    "    )\n",
    "    \n",
    "    signal_processed = preprocess_signal(signal, fs)\n",
    "    features = extract_features_from_segment(signal_processed, fs, prn)\n",
    "    features['label'] = 1 if is_spoofed else 0\n",
    "    features_list.append(features)\n",
    "\n",
    "df = pd.DataFrame(features_list)\n",
    "print(f\"\\nDataset created: {len(df)} segments\")\n",
    "print(f\"  Authentic: {sum(df['label'] == 0)}\")\n",
    "print(f\"  Spoofed:   {sum(df['label'] == 1)}\")\n",
    "print(f\"\\nFeature columns: {len(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Features\n",
    "\n",
    "Compare feature distributions between authentic and spoofed signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select key features to visualize\n",
    "key_features = ['peak_to_secondary', 'asymmetry', 'cn0_estimate', 'fwhm']\n",
    "\n",
    "plot_feature_distributions(df, key_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train Model\n",
    "\n",
    "Train a Random Forest classifier to detect spoofing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feature_cols = [col for col in df.columns if col != 'label']\n",
    "X = df[feature_cols].values\n",
    "y = df['label'].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = create_train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "# Train model\n",
    "model, cv_results = train_model(\n",
    "    X_train, y_train,\n",
    "    model_name='random_forest',\n",
    "    balance_method='class_weight',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model\n",
    "\n",
    "Evaluate the trained model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "results = evaluate_model(model, X_test, y_test, verbose=True)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(results['confusion_matrix'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Importance\n",
    "\n",
    "Analyze which features are most important for spoofing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.evaluation import get_feature_importance\n",
    "from src.utils.plots import plot_feature_importance\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = get_feature_importance(model, feature_cols, top_n=15)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(importance_df.head(10).to_string(index=False))\n",
    "\n",
    "# Plot\n",
    "plot_feature_importance(importance_df, top_n=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete pipeline:\n",
    "1. Signal generation (synthetic)\n",
    "2. Preprocessing\n",
    "3. Feature extraction\n",
    "4. Model training\n",
    "5. Evaluation\n",
    "\n",
    "The model successfully distinguishes between authentic and spoofed GPS signals using correlation-based features and statistical metrics.\n",
    "\n",
    "**Next steps**:\n",
    "- Try with real TEXBAT or FGI dataset\n",
    "- Compare different models (SVM, MLP)\n",
    "- Tune hyperparameters\n",
    "- Analyze failure cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
