{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction Demo - GPS Spoofing Detection\n",
    "\n",
    "This notebook demonstrates the feature extraction pipeline for GPS spoofing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from utils.synthetic_data import generate_synthetic_dataset\n",
    "from preprocessing.signal_processing import generate_ca_code\n",
    "from features.pipeline import build_feature_vector, build_feature_dataframe, preprocess_features\n",
    "from utils.plots import plot_feature_distributions\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic signals\n",
    "signals, labels, metadata = generate_synthetic_dataset(\n",
    "    num_authentic=50,\n",
    "    num_spoofed=50,\n",
    "    fs=5e6,\n",
    "    duration=0.5,\n",
    "    prn_range=(1, 5),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(signals)} signals\")\n",
    "print(f\"Authentic: {sum(1 for l in labels if l == 0)}\")\n",
    "print(f\"Spoofed: {sum(1 for l in labels if l == 1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract Features from Single Signal\n",
    "\n",
    "Demonstrate feature extraction for a single signal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select first signal\n",
    "signal = signals[0]\n",
    "prn = metadata[0]['prn']\n",
    "label = labels[0]\n",
    "\n",
    "# Generate PRN code\n",
    "ca_code = generate_ca_code(prn)\n",
    "\n",
    "# Extract features\n",
    "features = build_feature_vector(\n",
    "    signal=signal,\n",
    "    prn_code=ca_code,\n",
    "    fs=5e6,\n",
    "    label=label,\n",
    "    metadata={'prn': prn, 'segment_index': 0}\n",
    ")\n",
    "\n",
    "# Display features\n",
    "print(\"\\nExtracted Features:\")\n",
    "print(\"=\"*60)\n",
    "for key, value in sorted(features.items()):\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:25s}: {value:12.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:25s}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Complete Feature DataFrame\n",
    "\n",
    "Extract features for all signals and create a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for all signals\n",
    "print(\"Extracting features for all signals...\")\n",
    "\n",
    "all_features = []\n",
    "for i, signal in enumerate(signals):\n",
    "    prn = metadata[i]['prn']\n",
    "    ca_code = generate_ca_code(prn)\n",
    "    \n",
    "    features = build_feature_vector(\n",
    "        signal=signal,\n",
    "        prn_code=ca_code,\n",
    "        fs=5e6,\n",
    "        label=labels[i],\n",
    "        metadata={'prn': prn, 'segment_index': i}\n",
    "    )\n",
    "    all_features.append(features)\n",
    "\n",
    "# Create DataFrame\n",
    "df_features = pd.DataFrame(all_features)\n",
    "\n",
    "print(f\"\\nFeature DataFrame shape: {df_features.shape}\")\n",
    "print(f\"\\nColumns: {list(df_features.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Statistics and Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric features (exclude metadata)\n",
    "feature_cols = [col for col in df_features.columns if col not in ['label', 'prn', 'segment_index']]\n",
    "\n",
    "# Summary statistics\n",
    "print(\"Feature Summary Statistics:\")\n",
    "print(\"=\"*80)\n",
    "df_features[feature_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlation matrix for key features\n",
    "key_features = ['peak_height', 'peak_to_secondary', 'fwhm', 'fpw', 'asymmetry', \n",
    "                'cn0_estimate', 'total_power', 'snr_estimate']\n",
    "available_features = [f for f in key_features if f in df_features.columns]\n",
    "\n",
    "corr_matrix = df_features[available_features].corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Feature Distributions\n",
    "\n",
    "Compare feature distributions between authentic and spoofed signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot key feature distributions\n",
    "key_features = ['peak_height', 'peak_to_secondary', 'fpw', 'asymmetry', \n",
    "                'cn0_estimate', 'snr_estimate', 'total_power', 'fwhm']\n",
    "available_features = [f for f in key_features if f in df_features.columns]\n",
    "\n",
    "plot_feature_distributions(\n",
    "    df_features,\n",
    "    features=available_features,\n",
    "    label_col='label',\n",
    "    figsize=(16, 12)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Preprocessing\n",
    "\n",
    "Demonstrate feature preprocessing (imputation, scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features for modeling\n",
    "X = df_features.drop(columns=['label', 'prn', 'segment_index'], errors='ignore')\n",
    "y = df_features['label'].values\n",
    "\n",
    "# Preprocess features\n",
    "X_processed, imputer, scaler, _ = preprocess_features(\n",
    "    X, y,\n",
    "    fit=True\n",
    ")\n",
    "\n",
    "print(f\"\\nOriginal feature shape: {X.shape}\")\n",
    "print(f\"Processed feature shape: {X_processed.shape}\")\n",
    "print(f\"\\nProcessed features (first 5 samples):\")\n",
    "print(X_processed[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "Use a simple Random Forest to assess feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train simple model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "rf.fit(X_processed, y)\n",
    "\n",
    "# Get feature importances\n",
    "feature_names = [col for col in X.columns]\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Sort by importance\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(range(len(indices)), importances[indices])\n",
    "plt.yticks(range(len(indices)), [feature_names[i] for i in indices])\n",
    "plt.xlabel('Feature Importance', fontsize=12)\n",
    "plt.title('Feature Importance (Random Forest)', fontsize=14, fontweight='bold')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print top features\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "for i in range(min(10, len(indices))):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]:25s}: {importances[indices[i]]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Feature Dataset\n",
    "\n",
    "Save the extracted features for use in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "output_path = '../data/processed/features_demo.csv'\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"Features saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key features for GPS spoofing detection:\n",
    "\n",
    "**Correlation-based (SQMs):**\n",
    "- `peak_to_secondary`: Ratio of primary to secondary peak (decreases with spoofing)\n",
    "- `fpw`: Fractional Peak Width (increases with spoofing)\n",
    "- `asymmetry`: Peak asymmetry (changes with synchronized spoofing)\n",
    "\n",
    "**Power-based:**\n",
    "- `cn0_estimate`: Carrier-to-Noise ratio (increases with power attacks)\n",
    "- `total_power`: Signal power (often elevated in spoofing)\n",
    "\n",
    "Next: See `training_eval.ipynb` for model training and evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
